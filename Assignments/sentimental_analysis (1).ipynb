{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0HTIJsnLPrz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In this i have done two sets mainly due to heavy training dataset.Due to huge training time i reduced the epoch to 1,so model didnt train well .As a result,the emotions are not cathing perfectly in the ouput.\n",
        "\n",
        "##Second attempt done on selecting random samples from the dataset by balancing all the three sets.Eventhough this outperforms the previous,still have some issues on the output"
      ],
      "metadata": {
        "id": "d42HfiaJ7HYh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd3i9bR2LQhn"
      },
      "source": [
        "Objective:\n",
        "Develop machine learning models to classify emotions in text samples.\n",
        "Dataset:\n",
        "https://drive.google.com/file/d/1HWczIICsMpaL8EJyu48ZvRFcXx3_pcnb/view?usp=drive_link\n",
        "Key components to be fulfilled :\n",
        "1. Loading and Preprocessing (3 marks)\n",
        "● Load the dataset and perform necessary preprocessing steps. This should include text\n",
        "cleaning, tokenization, and removal of stopwords. Explain the preprocessing techniques\n",
        "used and their impact on model performance.\n",
        "2. Feature Extraction (2 marks):\n",
        "● Implement feature extraction using CountVectorizer or TfidfVectorizer. Describe how the\n",
        "chosen method transforms the text data into numerical features.\n",
        "3. Model Development (2 marks):\n",
        "● Train the following machine learning models\n",
        "a)Naive Bayesb)Support Vector Machine\n",
        "\n",
        "4. Model Comparison (2 marks)\n",
        "● Evaluate the model using appropriate metrics (e.g., accuracy, F1-score). Provide a brief\n",
        "explanation of the chosen model and its suitability for emotion classification.\n",
        "5.Timely Submission (1 mark)\n",
        "Submission Guidelines\n",
        "● Provide your code in a Jupyter Notebook format and submit the GitHub link here.\n",
        "● Ensure your explanations and answers are clear and concise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MZfsemXCLRaS",
        "outputId": "d9b650b0-75e7-4849-c7fd-9f5ef73a0adc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Comment Emotion\n",
              "0  i seriously hate one subject to death but now ...    fear\n",
              "1                 im so full of life i feel appalled   anger\n",
              "2  i sit here to write i start to dig out my feel...    fear\n",
              "3  ive been really angry with r and i feel like a...     joy\n",
              "4  i feel suspicious if there is no one outside l...    fear"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c42ee945-86f8-4062-a9bc-043270cfbfa8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i seriously hate one subject to death but now ...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im so full of life i feel appalled</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i sit here to write i start to dig out my feel...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ive been really angry with r and i feel like a...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i feel suspicious if there is no one outside l...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c42ee945-86f8-4062-a9bc-043270cfbfa8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c42ee945-86f8-4062-a9bc-043270cfbfa8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c42ee945-86f8-4062-a9bc-043270cfbfa8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5937,\n  \"fields\": [\n    {\n      \"column\": \"Comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5934,\n        \"samples\": [\n          \"i male are stupid first for woman cry babies and should get over it and you feel really cool for putting the stupid men in their place\",\n          \"im feeling queezy and cant be bothered putting these in order so here goes\",\n          \"i feel completely agitated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Emotion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"fear\",\n          \"anger\",\n          \"joy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Loading dataset\n",
        "df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1HWczIICsMpaL8EJyu48ZvRFcXx3_pcnb\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "D7AeFbTid-c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "S2RKVWRAR9Gt",
        "outputId": "b8242567-b457-4d67-f400-48ee78d688e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Emotion\n",
              "anger    4000000\n",
              "joy      4000000\n",
              "fear     3751969\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotion</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>4000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>4000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>3751969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_tags(text):\n",
        "    text = re.sub(r'<.*?>', '', text)           # remove HTML tags\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # remove URLs\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)        # remove punctuation\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "df['Comment']=df['Comment'].apply(lambda cw : remove_tags(cw))"
      ],
      "metadata": {
        "id": "-IwKd1skSDmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['Comment'] = df['Comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjDjBu7QUXpA",
        "outputId": "274722f9-9af4-46e2-f9ca-018a11e9eb48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization (To perform this,we need wordnet corpus which usually finds the synonyms,antonyms etc)\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['Comment']=df['Comment'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvhLQYLiaVLo",
        "outputId": "5bd028e2-d2aa-490f-f5ba-1bfc43104473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- Average Review Length (in words) -----\n",
        "df['review_length'] = df['Comment'].apply(lambda x: len(str(x).split()))\n",
        "average_length = df['review_length'].mean()\n",
        "# ----- Emotion Percentage Distribution -----\n",
        "emotion_percentages = df['Emotion'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"Average length of each review (in words): {:.2f}\".format(average_length))\n",
        "print(\"\\nEmotion Distribution (%):\")\n",
        "\n",
        "for emotion, percentage in emotion_percentages.items():\n",
        "    print(f\"{emotion}: {percentage:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlVivlJ1eaPO",
        "outputId": "b08c1806-e8bd-43cb-ed49-029905707fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length of each review (in words): 9.38\n",
            "\n",
            "Emotion Distribution (%):\n",
            "anger: 33.69%\n",
            "joy: 33.69%\n",
            "fear: 32.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "0cvqnsSiqwLI",
        "outputId": "5ab61d22-e467-4096-ebfd-e9831b89aa83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Comment          11751969\n",
              "Emotion          11751969\n",
              "review_length    11751969\n",
              "Emotion_label    11751969\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Comment</th>\n",
              "      <td>11751969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotion</th>\n",
              "      <td>11751969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_length</th>\n",
              "      <td>11751969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotion_label</th>\n",
              "      <td>11751969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df['Emotion_label'] = label_encoder.fit_transform(df['Emotion'])\n",
        "df=df.merge(df['Emotion_label'])\n",
        "df.head()\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "-tCDT_tCSc7D",
        "outputId": "03056776-f810-4b71-8658-204342a5ee95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Emotion_label\n",
              "0    4000000\n",
              "2    4000000\n",
              "1    3751969\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Emotion_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3751969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df['Emotion_label'].unique()\n",
        "df['Emotion_label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train test split"
      ],
      "metadata": {
        "id": "Kl_51czdeE2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp-V_zq3Sy22"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Comment'], df['Emotion_label'], test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxfFxIx6YHUG"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters of the model\n",
        "vocab_size = 3000 # choose based on statistics\n",
        "oov_tok = ''\n",
        "embedding_dim = 100\n",
        "max_length = 10 # choose based on statistics, for example 150 to 200\n",
        "padding_type='post'\n",
        "trunc_type='post'\n",
        "# tokenize sentences\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "word_index = tokenizer.word_index\n",
        "# convert train dataset to sequence and pad sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
        "# convert Test dataset to sequence and pad sequences\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "D5KDIo3GZcxZ",
        "outputId": "890f17a8-b9e7-4c5e-8765-fe5ce5a1211d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m300,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m84,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m3,096\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">300,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,096</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m387,601\u001b[0m (1.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">387,601</span> (1.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m387,601\u001b[0m (1.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">387,601</span> (1.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "# model initialization\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "    keras.layers.Dense(24, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "# compile model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.build(input_shape=(None, max_length))\n",
        "# model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "history = model.fit(train_padded, y_train,\n",
        "                    epochs=num_epochs, verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37oLbN1_ojY0",
        "outputId": "a8a3e406-fb82-46a4-9547-634fd40fc9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m264420/264420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2151s\u001b[0m 8ms/step - accuracy: 0.6212 - loss: -5205481.0000 - val_accuracy: 0.6371 - val_loss: -45275868.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save=model.save(\"history.keras\")"
      ],
      "metadata": {
        "id": "mwTkRdiuuz_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predict probabilities on test data\n",
        "prediction = model.predict(test_padded)\n",
        "\n",
        "# Convert probabilities → class index\n",
        "pred_classes = np.argmax(prediction, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, pred_classes)\n",
        "print(\"Accuracy on test set:\", accuracy)\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    pred_classes,\n",
        "    target_names=label_encoder.classes_\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1l47Yn4r1sY",
        "outputId": "822edd89-4266-4bea-93ac-acc0675ad645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m73450/73450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3ms/step\n",
            "Accuracy on test set: 0.3396464592744876\n",
            "\n",
            "Classification Report:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.34      1.00      0.51    798303\n",
            "        fear       0.00      0.00      0.00    751151\n",
            "         joy       0.00      0.00      0.00    800940\n",
            "\n",
            "    accuracy                           0.34   2350394\n",
            "   macro avg       0.11      0.33      0.17   2350394\n",
            "weighted avg       0.12      0.34      0.17   2350394\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence to predict\n",
        "sentence = [\"I am sitting alone scared\"]\n",
        "\n",
        "# Convert text → sequence\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "\n",
        "# Pad sequence\n",
        "padded = pad_sequences(sequences, padding='post', maxlen=max_length)\n",
        "\n",
        "# Predict probabilities\n",
        "prediction = model.predict(padded)\n",
        "\n",
        "# Get class index\n",
        "pred_class = np.argmax(prediction, axis=1)\n",
        "\n",
        "# Convert index → actual emotion label\n",
        "pred_label = label_encoder.inverse_transform(pred_class)\n",
        "\n",
        "print(\"Sentence:\", sentence[0])\n",
        "print(\"Predicted Emotion:\", pred_label[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th8NOINdtRMn",
        "outputId": "d96460c2-a3f2-4fa4-d60f-eba5d992a759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "Sentence: I am sitting alone scared\n",
            "Predicted Emotion: anger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Test"
      ],
      "metadata": {
        "id": "KADoku7d7t_E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5lFuuwiygF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#\n",
        "df = pd.read_csv(\"https://drive.google.com/uc?export=download&id=1HWczIICsMpaL8EJyu48ZvRFcXx3_pcnb\")\n",
        "\n",
        "# due to large training dataset,for me its not working so reducing the training set\n",
        "if len(df) > 100000:\n",
        "    df = df.sample(n=100000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 2. Text Preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<.*?>', '', str(text))\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "\n",
        "    words = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "df['Clean_Comment'] = df['Comment'].apply(clean_text)\n",
        "\n",
        "# 3. Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['Emotion_label'] = label_encoder.fit_transform(df['Emotion'])\n",
        "\n",
        "\n",
        "# 4. Feature Extraction (Tokenization & Padding)\n",
        "vocab_size = 5000\n",
        "max_length = 50\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Clean_Comment'], df['Emotion_label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# 5. Model Development\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(vocab_size, 64, input_length=max_length),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
        "    keras.layers.Dense(24, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    # Use 3 units for Joy, Fear, Anger and 'softmax' for probability distribution\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 6. Training\n",
        "num_epochs = 5\n",
        "history = model.fit(\n",
        "    train_padded, y_train,\n",
        "    epochs=num_epochs,\n",
        "    validation_split=0.1,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# 7. Evaluation\n",
        "predictions = model.predict(test_padded)\n",
        "pred_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, pred_classes))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, pred_classes, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8KwLx-u57F6",
        "outputId": "ebdb4218-4f42-41f7-c9b6-bfa4bb6ed1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.4015 - loss: 1.0661 - val_accuracy: 0.6042 - val_loss: 0.8347\n",
            "Epoch 2/5\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8985 - loss: 0.3379 - val_accuracy: 0.9116 - val_loss: 0.2748\n",
            "Epoch 3/5\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9761 - loss: 0.0803 - val_accuracy: 0.8989 - val_loss: 0.2952\n",
            "Epoch 4/5\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0469 - val_accuracy: 0.9053 - val_loss: 0.2902\n",
            "Epoch 5/5\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9962 - loss: 0.0253 - val_accuracy: 0.8968 - val_loss: 0.4508\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\n",
            "Accuracy: 0.8973063973063973\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.92      0.84      0.88       392\n",
            "        fear       0.88      0.94      0.91       416\n",
            "         joy       0.90      0.91      0.90       380\n",
            "\n",
            "    accuracy                           0.90      1188\n",
            "   macro avg       0.90      0.90      0.90      1188\n",
            "weighted avg       0.90      0.90      0.90      1188\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(text):\n",
        "    # 1. Clean the input text\n",
        "    cleaned_text = clean_text(text)\n",
        "    # 2. Tokenize and pad (using the same tokenizer from training)\n",
        "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
        "    padded = pad_sequences(sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "    # 3. Predict\n",
        "    prediction = model.predict(padded)\n",
        "    # 4. Get the label with the highest probability\n",
        "    class_index = np.argmax(prediction)\n",
        "    emotion = label_encoder.inverse_transform([class_index])[0]\n",
        "    # Optional: Print confidence scores\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"Predicted Emotion: {emotion}\")\n",
        "    for i, prob in enumerate(prediction[0]):\n",
        "        print(f\"{label_encoder.classes_[i]}: {prob*100:.2f}%\")\n",
        "\n",
        "# Testing\n",
        "predict_emotion(\"I am so happy that I passed the exam!\")\n",
        "predict_emotion(\"I heard a strange noise in the dark and got terrified.\")\n",
        "predict_emotion(\"It makes me so mad when people lie to me.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBYgrV6s6K47",
        "outputId": "69f53123-81a9-4ecc-cace-c253d5a8e5ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
            "\n",
            "Text: I am so happy that I passed the exam!\n",
            "Predicted Emotion: anger\n",
            "anger: 90.08%\n",
            "fear: 3.63%\n",
            "joy: 6.29%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
            "\n",
            "Text: I heard a strange noise in the dark and got terrified.\n",
            "Predicted Emotion: fear\n",
            "anger: 0.00%\n",
            "fear: 100.00%\n",
            "joy: 0.00%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\n",
            "Text: It makes me so mad when people lie to me.\n",
            "Predicted Emotion: anger\n",
            "anger: 99.30%\n",
            "fear: 0.60%\n",
            "joy: 0.10%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}